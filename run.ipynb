{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1dca7-635d-4e7f-8802-a8658138574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socket instantiated\n",
      "socket binded\n",
      "socket now listening\n",
      "socket accepted, got connection object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading Face model: retinaface\n",
      "INFO:root:Loading Facial Landmark model: mobilefacenet\n",
      "INFO:root:Loading facepose model: img2pose\n",
      "INFO:root:Loading AU model: xgb\n",
      "INFO:root:Loading emotion model: resmasknet\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 292, 292]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 286, 286]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51642215 0.62610203 0.18544568 0.338875   0.15816067 0.\n",
      " 0.08203869 0.15423019 0.         0.1130346  0.4308314  0.56682825\n",
      " 0.59844303 0.         0.7645371  0.6872861  0.0694216  0.10404256\n",
      " 0.3237554  0.04274102]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[322, 35, 490, 280, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 306, 312]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7692344  0.65719944 0.6968758  0.28157622 0.22542226 0.\n",
      " 0.36213478 0.2627855  1.         0.1703242  0.5686184  0.6184138\n",
      " 0.6391954  0.         0.71127695 0.74206746 0.3530822  0.33587536\n",
      " 0.54813784 0.8332886 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[298, 31, 466, 270, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 307, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5862806  0.6741178  0.21230464 0.32613632 0.15023974 0.\n",
      " 0.08036272 0.11012694 0.         0.07748674 0.30656046 0.4529618\n",
      " 0.5224016  0.         0.7300276  0.5972149  0.04085206 0.12952274\n",
      " 0.779243   0.11746118]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[297, 20, 475, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 306, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49883366 0.5224838  0.1504894  0.6986339  0.09520791 0.\n",
      " 0.08055702 0.05453913 0.         0.0858501  0.40500087 0.34957242\n",
      " 0.5712468  0.         0.692423   0.69708574 0.06054535 0.1532086\n",
      " 0.38611743 0.03127868]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 19, 473, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5226802  0.45131466 0.19518353 0.746634   0.1135469  0.\n",
      " 0.07557158 0.09340665 0.         0.095521   0.21833552 0.2919792\n",
      " 0.465385   0.         0.57913625 0.58984786 0.07716023 0.17784785\n",
      " 0.33691144 0.02889127]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 18, 478, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 310, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6763396  0.6556664  0.20684804 0.2629707  0.16861293 0.\n",
      " 0.0992032  0.05825343 0.         0.0922813  0.26206085 0.43057072\n",
      " 0.56895894 0.         0.50767416 0.804869   0.05331123 0.0653098\n",
      " 0.8620954  0.09517802]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 22, 477, 286, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6550848  0.5443438  0.20632726 0.32837898 0.12752299 0.\n",
      " 0.08630732 0.6891508  0.         0.07217515 0.42503136 0.44750834\n",
      " 0.6018963  0.         0.7321369  0.7925036  0.14128284 0.19372167\n",
      " 0.5138501  0.09172969]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 19, 477, 285, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55638975 0.4245024  0.139023   0.3353918  0.12791003 0.\n",
      " 0.07421209 0.07716329 0.         0.06476779 0.31344625 0.40321663\n",
      " 0.535541   0.         0.7747171  0.80283386 0.01482544 0.11111937\n",
      " 0.5342408  0.06648742]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[302, 22, 481, 284, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54474056 0.4991747  0.22065152 0.32360834 0.13033529 0.\n",
      " 0.07118739 0.13630672 0.         0.10705867 0.4701649  0.32129446\n",
      " 0.522656   0.         0.7559491  0.78326744 0.06804925 0.09289635\n",
      " 0.57317084 0.02866682]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[300, 18, 481, 286, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 311, 318]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 313, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47575065 0.29733586 0.25333458 0.24342217 0.11823238 0.\n",
      " 0.07546364 0.11285707 0.         0.08140667 0.4484721  0.2505852\n",
      " 0.5498978  0.         0.7872693  0.7219357  0.11618792 0.12489033\n",
      " 0.4313716  0.0269542 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 19, 481, 286, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 310, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48114687 0.29625252 0.22141373 0.32633436 0.15826418 0.\n",
      " 0.0901989  0.20167902 0.         0.17234522 0.38295585 0.5075312\n",
      " 0.54974115 0.         0.66792315 0.8080914  0.01645378 0.07739501\n",
      " 0.32481346 0.0453258 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 21, 482, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5507623  0.3716499  0.22960185 0.6547209  0.10115948 0.\n",
      " 0.06918461 0.2610824  0.         0.06603546 0.5637109  0.13293\n",
      " 0.592491   0.         0.66659117 0.7012892  0.03324913 0.12497634\n",
      " 0.17785092 0.05048079]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 20, 482, 285, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 312]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45025736 0.45362285 0.2146186  0.71986216 0.11160592 0.\n",
      " 0.08145455 0.0164556  0.         0.08159231 0.553988   0.16574366\n",
      " 0.56936836 0.         0.80153155 0.65805    0.02110209 0.08860689\n",
      " 0.7021808  0.02249485]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 21, 484, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 315, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4258142  0.2967773  0.2645029  0.35923186 0.1399409  0.\n",
      " 0.09557669 0.00335303 0.         0.07777886 0.41132417 0.20348932\n",
      " 0.6291037  0.         0.7226618  0.67864496 0.00720057 0.08309333\n",
      " 0.26872006 0.02606671]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 27, 479, 287, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 310]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38976243 0.31110126 0.23217548 0.23226047 0.15493853 0.\n",
      " 0.07391704 0.11289959 0.         0.17876604 0.4639291  0.54114264\n",
      " 0.5875441  0.         0.7217807  0.76447433 0.03415566 0.19684638\n",
      " 0.45833778 0.04745514]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 24, 481, 289, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 308]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6389431  0.60488737 0.85975224 0.22232729 0.2595998  0.\n",
      " 0.48894966 0.10662682 1.         0.15216072 0.6785623  0.54218745\n",
      " 0.6836081  0.         0.691866   0.8460885  0.11115826 0.2451822\n",
      " 0.5854867  0.91900843]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[303, 25, 479, 283, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 287, 294]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7243065  0.3466838  0.48955098 0.32497936 0.41225874 0.\n",
      " 0.32528198 0.53255737 1.         0.46394858 0.31420812 0.3563069\n",
      " 0.46913013 1.         0.49274528 0.04595401 0.99819547 0.9064078\n",
      " 0.44295046 0.50205576]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[308, 11, 484, 269, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 298, 304]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78975177 0.32009596 0.5168271  0.29098013 0.2676527  0.\n",
      " 0.2856399  0.29185817 1.         0.11662556 0.1583333  0.49957526\n",
      " 0.74326056 0.         0.5299622  0.6238044  0.504599   0.24616592\n",
      " 0.48753408 0.44331384]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[305, 17, 481, 264, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7831861  0.45105428 0.16040073 0.3399723  0.1647121  0.\n",
      " 0.14175867 0.20661089 0.         0.1291697  0.2354106  0.3201356\n",
      " 0.70358896 0.         0.40023586 0.7339398  0.05162908 0.36888224\n",
      " 0.2602133  0.09333711]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[304, 19, 481, 274, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27725676 0.38320184 0.30872437 0.28548178 0.12723032 0.\n",
      " 0.07375169 0.10722003 1.         0.12832877 0.31576163 0.3336053\n",
      " 0.5642216  0.         0.8246341  0.87121683 0.02682326 0.12325843\n",
      " 0.36303473 0.05077471]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[297, 21, 480, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 324, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4220997  0.37760097 0.4055394  0.32359895 0.13885698 0.\n",
      " 0.07300482 0.06410035 0.         0.10001532 0.34919798 0.16635841\n",
      " 0.51846    0.         0.68104154 0.8237466  0.02650264 0.10485446\n",
      " 0.79784364 0.03079594]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[296, 21, 482, 289, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 315, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34341156 0.28402618 0.5002222  0.28982538 0.10305475 0.\n",
      " 0.10526769 0.06886245 0.         0.09647273 0.29393208 0.5222854\n",
      " 0.49148253 0.         0.73516524 0.74697304 0.12405628 0.57996637\n",
      " 0.80374146 0.04565491]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[293, 20, 482, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 295, 300]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42811644 0.3020528  0.26671043 0.32436156 0.4114768  0.\n",
      " 0.11286587 0.2241012  0.         0.38230786 0.50998354 0.5174476\n",
      " 0.5595602  1.         0.72617644 0.6592171  0.85518545 0.3005789\n",
      " 0.39193732 0.0796741 ]\n",
      "['fear']\n",
      "sending: {\"faces_pos\": [[297, 17, 478, 288, 1]], \"emotions\": [\"fear\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 300, 310]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6569735  0.5034768  0.32873788 0.38852093 0.15980625 0.\n",
      " 0.15329581 0.06531253 0.         0.04187961 0.2737347  0.52936286\n",
      " 0.40558887 0.         0.5343355  0.2008355  0.9870314  0.6492996\n",
      " 0.3522651  0.05528947]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[304, 20, 480, 272, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5930338  0.30056983 0.41046983 0.3749002  0.14752637 0.\n",
      " 0.25483856 0.23527305 1.         0.04461341 0.21841715 0.5944515\n",
      " 0.53354055 0.         0.72106075 0.52674073 0.5713579  0.2428774\n",
      " 0.2474191  0.09252977]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 16, 475, 275, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 315, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 302, 312]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2947543  0.20972116 0.28424367 0.32360834 0.11813892 1.\n",
      " 0.08134124 0.10251749 0.         0.06517223 0.5070705  0.21032456\n",
      " 0.53028214 0.         0.60511273 0.81877947 0.01106568 0.1893743\n",
      " 0.6045698  0.0492597 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[298, 16, 484, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 278, 282]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37040323 0.12708654 0.6627261  0.23378536 0.14372233 0.\n",
      " 0.12204145 0.08300685 0.         0.05779068 0.37493634 0.40097\n",
      " 0.4812795  0.         0.37381783 0.5419494  0.60614544 0.49857154\n",
      " 0.2696783  0.22062181]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 16, 475, 277, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 295, 300]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7516105  0.32630342 0.54058135 0.27795252 0.1828596  0.\n",
      " 0.3415638  0.04744488 1.         0.07894181 0.10726742 0.69156647\n",
      " 0.58926404 0.         0.4564849  0.3030168  0.8118377  0.62024605\n",
      " 0.18001625 0.86157334]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[284, 20, 448, 255, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 313, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33994246 0.16370264 0.59999835 0.33113724 0.2015111  1.\n",
      " 0.1756086  0.4164012  1.         0.05578219 0.31297213 0.6341889\n",
      " 0.4996374  0.         0.7857542  0.45983097 0.97355855 0.89279824\n",
      " 0.39359355 0.05567751]\n",
      "['angry']\n",
      "sending: {\"faces_pos\": [[277, 20, 447, 271, 1]], \"emotions\": [\"angry\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2249523  0.15576862 0.70095587 0.32814276 0.10509879 1.\n",
      " 0.11748702 0.848294   1.         0.07107665 0.4332629  0.347229\n",
      " 0.40079853 0.         0.60924655 0.63646215 0.24091847 0.68435967\n",
      " 0.6459629  0.06040557]\n",
      "['fear']\n",
      "sending: {\"faces_pos\": [[278, 18, 454, 287, 1]], \"emotions\": [\"fear\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34665623 0.26212052 0.6344452  0.31431144 0.10443049 0.\n",
      " 0.09007687 0.74522877 0.         0.09912056 0.358545   0.650489\n",
      " 0.55030674 0.         0.7295237  0.7729081  0.19746709 0.3397026\n",
      " 0.6560396  0.04420459]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 19, 465, 287, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 322, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17666727 0.1690351  0.24723998 0.24392693 0.10801099 0.\n",
      " 0.08624233 0.7106994  0.         0.14707746 0.59059536 0.24139293\n",
      " 0.51456714 0.         0.6946411  0.4446412  0.11887199 0.21219766\n",
      " 0.08083089 0.03602317]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 29, 486, 299, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 325, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11662027 0.27834943 0.30190125 0.62246376 0.10800081 0.\n",
      " 0.0955314  0.02760603 0.         0.08602925 0.37080798 0.09349515\n",
      " 0.59981954 0.         0.6705605  0.7477221  0.02749202 0.17300214\n",
      " 0.7022626  0.03295673]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[293, 31, 482, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 327, 330]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23815095 0.20919538 0.5477142  0.3592503  0.06839372 0.\n",
      " 0.09466425 0.11510248 0.         0.05547277 0.4350317  0.43776506\n",
      " 0.5823443  0.         0.8431456  0.7678761  0.02872307 0.11427112\n",
      " 0.64668864 0.0316623 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[290, 21, 482, 298, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 322, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20885308 0.2030959  0.5330061  0.2389213  0.07703903 0.\n",
      " 0.09633166 0.04701791 0.         0.05487111 0.36116737 0.4563155\n",
      " 0.5945824  0.         0.5869052  0.83987284 0.02610529 0.06693701\n",
      " 0.40923288 0.03550392]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[294, 25, 479, 301, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21129869 0.21802396 0.6210565  0.29347345 0.08905739 0.\n",
      " 0.10722622 0.05029778 1.         0.12300162 0.4073463  0.27102\n",
      " 0.567957   0.         0.8463755  0.7974127  0.01999906 0.14710993\n",
      " 0.70629305 0.02897122]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 32, 480, 301, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21388334 0.24843204 0.34859228 0.31068805 0.08509444 0.\n",
      " 0.08460586 0.05865806 0.         0.07787    0.2241023  0.49424094\n",
      " 0.5607074  0.         0.81922424 0.875282   0.00855586 0.19475967\n",
      " 0.37865385 0.03236896]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[290, 36, 477, 302, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 322, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23610114 0.20441237 0.5435105  0.21921708 0.14468025 0.\n",
      " 0.11307228 0.7387279  0.         0.10317922 0.44159827 0.29130533\n",
      " 0.5352049  0.         0.7192934  0.84049094 0.02808672 0.1878831\n",
      " 0.61691517 0.06377506]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 36, 478, 300, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16488904 0.1718103  0.5329864  0.3325647  0.1084663  0.\n",
      " 0.10088877 0.12379324 0.         0.03789862 0.14287479 0.41843086\n",
      " 0.4693065  0.         0.616024   0.7161267  0.03309961 0.39071217\n",
      " 0.5645448  0.04658064]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 37, 480, 306, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45360112 0.2719985  0.6001312  0.23832107 0.21148923 0.\n",
      " 0.22342451 0.6041829  0.         0.18761416 0.241674   0.23387563\n",
      " 0.5038948  0.         0.58641    0.65882367 0.2180972  0.19703524\n",
      " 0.4646502  0.24514657]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 35, 488, 301, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 327, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4464516  0.15103495 0.7212455  0.23236564 0.12447082 0.\n",
      " 0.51932293 0.0195686  1.         0.0395193  0.3806798  0.3421998\n",
      " 0.56603765 0.         0.63513774 0.7896226  0.17554773 0.1492951\n",
      " 0.2187205  0.20028602]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 30, 484, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 324, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38482073 0.3813354  0.3173571  0.42043296 0.1991221  0.\n",
      " 0.10087568 0.6069662  0.         0.02715447 0.14895378 0.50906503\n",
      " 0.46950856 1.         0.5535263  0.56495523 0.9724698  0.50780195\n",
      " 0.21853665 0.03242548]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[296, 26, 482, 301, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 326, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20406906 0.17582199 0.8867138  0.22909343 0.11338808 0.\n",
      " 0.2619692  0.05603787 1.         0.05283469 0.25527295 0.3761466\n",
      " 0.50592774 0.         0.7679196  0.76010025 0.0108941  0.1605408\n",
      " 0.22513467 0.69393253]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[297, 37, 488, 308, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25942478 0.3487286  0.4618837  0.36027893 0.06474155 1.\n",
      " 0.0869841  0.03167717 1.         0.0408328  0.3798358  0.5137776\n",
      " 0.5664286  0.         0.80521476 0.69760394 0.10042833 0.6176118\n",
      " 0.42191222 0.0379778 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 32, 483, 306, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 294, 296]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 296]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81097627 0.70576924 0.19939078 0.21448365 0.57078207 0.\n",
      " 0.22336057 0.09526478 1.         0.5106312  0.51911306 0.5179036\n",
      " 0.5808772  0.         0.62088835 0.7637816  0.00616687 0.20620044\n",
      " 0.157695   0.13200825]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[298, 23, 472, 271, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 285, 298]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7640683  0.4457117  0.3800295  0.3062636  0.7165517  1.\n",
      " 0.31038514 0.95774984 0.         0.780756   0.44986773 0.18792862\n",
      " 0.36240685 1.         0.2990795  0.29850262 0.9990927  0.50974655\n",
      " 0.52996004 0.10691833]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[300, 21, 472, 269, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 292, 304]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69980234 0.3128432  0.5316559  0.26923108 0.6294947  0.\n",
      " 0.43428418 0.7211981  1.         0.6944415  0.37239444 0.19901162\n",
      " 0.47136503 1.         0.19925448 0.05620548 0.9978428  0.669212\n",
      " 0.5116637  0.35539824]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[292, 12, 467, 261, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 308]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68755114 0.5274205  0.68417954 0.26944953 0.82836074 1.\n",
      " 0.4968662  0.19878805 1.         0.953236   0.40626356 0.15501648\n",
      " 0.41828573 1.         0.15736523 0.10632204 0.99958676 0.5936216\n",
      " 0.22830905 0.21406941]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[295, 13, 467, 267, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5974132  0.50288    0.6672184  0.3229713  0.78921145 1.\n",
      " 0.48185667 0.8942995  1.         0.8964411  0.4826558  0.17052943\n",
      " 0.35256574 1.         0.4090652  0.09251405 0.99936444 0.574909\n",
      " 0.23410091 0.33910248]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[292, 10, 461, 268, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 295, 306]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 305, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8564525  0.5756971  0.2827156  0.32645005 0.26820973 0.\n",
      " 0.14277355 0.6972624  1.         0.42265227 0.48305947 0.3320745\n",
      " 0.52044183 0.         0.4770152  0.5910787  0.9213244  0.36982244\n",
      " 0.7417563  0.10684507]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[294, 15, 464, 270, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44874632 0.52819705 0.10913389 0.32560268 0.14596188 0.\n",
      " 0.09798932 0.17819439 0.         0.30622873 0.4760328  0.141529\n",
      " 0.5927464  0.         0.5961567  0.70153546 0.7928101  0.12073875\n",
      " 0.6814971  0.05584297]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[288, 15, 470, 279, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 308, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54107505 0.46866727 0.08884328 0.3255286  0.15065308 0.\n",
      " 0.0968958  0.23294497 0.         0.23468728 0.34584358 0.20453683\n",
      " 0.5769582  0.         0.66175336 0.7081598  0.08997394 0.04190505\n",
      " 0.5018806  0.07910421]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 20, 467, 283, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42622057 0.6152726  0.12754352 0.26505628 0.1517317  0.\n",
      " 0.12369896 0.01147682 0.         0.16694246 0.45118147 0.14135183\n",
      " 0.47621357 0.         0.7175378  0.6533479  0.13423434 0.08113679\n",
      " 0.53283596 0.06849883]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 20, 470, 283, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 313, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36125842 0.37507528 0.15789048 0.28387538 0.1467233  0.\n",
      " 0.09525314 0.3203288  0.         0.2359738  0.46248305 0.22771844\n",
      " 0.5197564  0.         0.7100865  0.77435315 0.6350278  0.08914861\n",
      " 0.26511198 0.06862053]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[294, 18, 471, 284, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 313, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.572757   0.5010388  0.1376729  0.3482893  0.18207878 0.\n",
      " 0.12307395 0.3929092  0.         0.26969364 0.6252751  0.3656298\n",
      " 0.501209   0.         0.77060294 0.7035662  0.27813426 0.04651868\n",
      " 0.40152258 0.0787655 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 18, 474, 287, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5315364  0.3863928  0.10514923 0.38251105 0.1518699  0.\n",
      " 0.13943113 0.5141185  0.         0.21684946 0.54027975 0.36177927\n",
      " 0.5002308  0.         0.5965423  0.7284922  0.12329159 0.08257252\n",
      " 0.30513498 0.06491245]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[292, 16, 476, 287, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 308, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42797744 0.5692264  0.10832956 0.6689859  0.1579325  0.\n",
      " 0.10975385 0.27425405 0.         0.29467368 0.69103956 0.2531537\n",
      " 0.45510498 0.         0.8203363  0.55979526 0.2119918  0.10275609\n",
      " 0.41163048 0.04287287]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[293, 19, 475, 286, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 315, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.474756   0.3710369  0.291539   0.3418021  0.05143972 0.\n",
      " 0.11872574 0.00330823 0.         0.02002617 0.12635216 0.7273276\n",
      " 0.6418848  0.         0.8368483  0.7522292  0.02829662 0.23056577\n",
      " 0.752502   0.04732696]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[274, 20, 448, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 313, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65388274 0.6002427  0.08645742 0.3769757  0.07397883 0.\n",
      " 0.11400243 0.00122224 0.         0.05537681 0.14618275 0.5650494\n",
      " 0.5913481  0.         0.6565436  0.58367693 0.03591661 0.2714204\n",
      " 0.7246064  0.04646986]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[279, 24, 462, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 315, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5407435  0.6007429  0.12119257 0.32782724 0.17846748 0.\n",
      " 0.09931252 0.6146202  1.         0.08543935 0.29756764 0.5140341\n",
      " 0.55103093 0.         0.84470665 0.70606196 0.06892958 0.40088314\n",
      " 0.33064926 0.06361485]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 14, 471, 287, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5315855  0.33529988 0.07646351 0.33203924 0.1454348  0.\n",
      " 0.12662004 0.06994477 1.         0.09533544 0.7489028  0.20670402\n",
      " 0.49778646 0.         0.74986947 0.7007137  0.02428137 0.5282135\n",
      " 0.80072117 0.08531788]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[297, 15, 477, 289, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3275724  0.34828106 0.07769508 0.37963542 0.09640612 0.\n",
      " 0.11589269 0.07606091 1.         0.09978025 0.4068239  0.28065884\n",
      " 0.5150802  0.         0.8808022  0.73647624 0.00546579 0.6590235\n",
      " 0.53220844 0.02309233]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[296, 17, 474, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 317, 330]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45394748 0.4535481  0.13220535 0.36903608 0.09405104 0.\n",
      " 0.09608793 0.38940004 0.         0.06305835 0.46033671 0.37625802\n",
      " 0.52285707 0.         0.8574005  0.87125754 0.00694761 0.43446812\n",
      " 0.5102832  0.05022376]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[297, 17, 476, 289, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41889238 0.3516055  0.09951426 0.38051394 0.07306259 0.\n",
      " 0.10469441 0.04426033 0.         0.06585804 0.32388705 0.5706784\n",
      " 0.5123434  0.         0.8851723  0.75567544 0.03891416 0.58441764\n",
      " 0.58330756 0.02592912]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[293, 15, 473, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 317, 324]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 324, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5908347  0.40362948 0.0978675  0.40022066 0.05421913 0.\n",
      " 0.09829024 0.02147197 1.         0.04793834 0.27599    0.35895914\n",
      " 0.51373994 0.         0.7922519  0.7309065  0.0103771  0.63128674\n",
      " 0.74254835 0.05282073]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 19, 469, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64292353 0.5067671  0.3185011  0.37205315 0.05710966 0.\n",
      " 0.1060416  0.06338619 1.         0.04312735 0.2968196  0.578444\n",
      " 0.46228912 0.         0.75342107 0.7781476  0.09897048 0.47030962\n",
      " 0.5092499  0.02781428]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[288, 19, 476, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7318283  0.38206616 0.13834351 0.28706208 0.12623377 0.\n",
      " 0.09996567 0.04043478 1.         0.07358972 0.31360394 0.20462342\n",
      " 0.4749064  0.         0.668287   0.38718423 0.97227603 0.82913834\n",
      " 0.8299094  0.05133467]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[284, 25, 468, 293, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 310, 316]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31223458 0.36337823 0.25726283 0.3453147  0.16428784 0.\n",
      " 0.08253785 0.02438287 0.         0.09447395 0.2723052  0.19658574\n",
      " 0.5091243  0.         0.6639858  0.6199039  0.84893113 0.61430603\n",
      " 0.64617425 0.03881009]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[288, 19, 462, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 291, 304]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43288663 0.54258317 0.205014   0.21448365 0.5495528  1.\n",
      " 0.24706165 0.276167   0.         0.67614126 0.7002123  0.29573268\n",
      " 0.69533855 0.         0.7704873  0.76882696 0.30882892 0.16324468\n",
      " 0.3110224  0.06575392]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[283, 20, 463, 285, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 304]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8035712  0.620762   0.3757031  0.3177783  0.53150105 1.\n",
      " 0.22392257 0.7217358  0.         0.70434827 0.5961998  0.31865704\n",
      " 0.62356836 0.         0.6899669  0.72055227 0.30233485 0.5113064\n",
      " 0.58898324 0.08204552]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[288, 13, 469, 267, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 292, 308]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7518638  0.58318067 0.36277485 0.31603533 0.7366175  0.\n",
      " 0.2982697  0.5618467  1.         0.8717239  0.4804527  0.34432033\n",
      " 0.27373683 1.         0.2479586  0.00984207 0.9992101  0.49918795\n",
      " 0.14882886 0.10218561]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[288, 14, 468, 269, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 295, 310]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6023071  0.41910592 0.32357448 0.2763373  0.5352608  1.\n",
      " 0.4601408  0.7223683  1.         0.6639665  0.56236845 0.36734027\n",
      " 0.54108596 1.         0.56429875 0.08018173 0.99712616 0.84945136\n",
      " 0.5502596  0.23555847]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[284, 10, 466, 267, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 296, 308]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8266747  0.48402137 0.7728104  0.47524023 0.72021616 0.\n",
      " 0.38218945 0.8907432  1.         0.8129325  0.41341838 0.08235434\n",
      " 0.3040497  1.         0.18314366 0.03726656 0.999895   0.64632446\n",
      " 0.18476476 0.13727386]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[283, 11, 468, 270, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8397052  0.58274937 0.5794128  0.41424423 0.7519362  0.\n",
      " 0.3671241  0.91365576 1.         0.8732254  0.4102282  0.06916366\n",
      " 0.408853   1.         0.3449255  0.11870133 0.999821   0.6114841\n",
      " 0.39809075 0.10276845]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[289, 13, 469, 271, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 303, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 305, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5943889  0.42860863 0.53967106 0.3080387  0.55325234 0.\n",
      " 0.19447757 0.8517008  1.         0.80198514 0.74765545 0.36723095\n",
      " 0.5498277  1.         0.7124695  0.54122263 0.99719197 0.29341242\n",
      " 0.62273705 0.11398288]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[284, 12, 461, 278, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 304, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6739606  0.62602526 0.23719366 0.31585556 0.5979943  0.\n",
      " 0.21781042 0.8844558  1.         0.7242641  0.69295704 0.25534004\n",
      " 0.50835484 1.         0.6794239  0.40623996 0.98959774 0.52043307\n",
      " 0.4840213  0.08462676]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[283, 14, 461, 280, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 296, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73359305 0.49612203 0.50463384 0.25951487 0.5768043  0.\n",
      " 0.40085474 0.9512985  1.         0.8148599  0.5762981  0.13574924\n",
      " 0.32907495 1.         0.40206265 0.12727198 0.99813324 0.41552302\n",
      " 0.3584779  0.22905505]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[290, 17, 470, 279, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 297, 312]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79123527 0.39272267 0.519629   0.32197702 0.78095573 0.\n",
      " 0.36091176 0.8180428  1.         0.9317809  0.42177895 0.17399345\n",
      " 0.35296613 1.         0.26678932 0.01562504 0.9993131  0.7101548\n",
      " 0.12183666 0.1484271 ]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[286, 9, 462, 271, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6391189  0.41889238 0.73837954 0.3080387  0.57072234 0.\n",
      " 0.32962632 0.83846813 1.         0.8385993  0.5671101  0.17948782\n",
      " 0.34407455 1.         0.554396   0.08046593 0.99190277 0.5595653\n",
      " 0.5060203  0.15895611]\n",
      "['happy']\n",
      "sending: {\"faces_pos\": [[286, 11, 462, 272, 1]], \"emotions\": [\"happy\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 276, 276]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 272, 272]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76713204 0.8242733  0.16635565 0.37107822 0.14973502 0.\n",
      " 0.08725318 0.11057571 0.         0.10727563 0.4415121  0.46981105\n",
      " 0.5309186  0.         0.5224308  0.7413474  0.13081688 0.06280807\n",
      " 0.5015125  0.0678184 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[312, 59, 475, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 272, 272]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.797256   0.59726614 0.13236666 0.33696845 0.12402784 0.\n",
      " 0.10238084 0.01883623 1.         0.03186568 0.40967762 0.36887035\n",
      " 0.5271285  0.         0.44249496 0.73675865 0.00747883 0.07606553\n",
      " 0.73823756 0.05765617]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 54, 450, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 284, 284]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7409765  0.655604   0.18188326 0.5219466  0.08406073 0.\n",
      " 0.17408691 0.00619801 1.         0.0486392  0.3274363  0.6956722\n",
      " 0.5696675  0.         0.6151123  0.44205755 0.18058476 0.13778676\n",
      " 0.9248178  0.13702162]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[277, 55, 444, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 278, 278]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45303813 0.20848086 0.8368929  0.22897072 0.22463337 1.\n",
      " 0.5943772  0.02199578 0.         0.1219585  0.38694078 0.736123\n",
      " 0.6051417  0.         0.71585596 0.68959326 0.39451882 0.4758226\n",
      " 0.2562958  0.4525022 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[314, 41, 480, 279, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 286, 286]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62323886 0.32674322 0.8791237  0.23638842 0.18351653 0.\n",
      " 0.34714225 0.02873197 1.         0.09975948 0.3909701  0.6919134\n",
      " 0.6811283  0.         0.5176038  0.7330712  0.05055414 0.09872995\n",
      " 0.56787986 0.566204  ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 43, 457, 275, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 290, 290]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45376867 0.1901547  0.91992134 0.2390181  0.3290315  0.\n",
      " 0.67233235 0.12054585 1.         0.15740117 0.5530696  0.7495369\n",
      " 0.6486028  0.         0.573512   0.14728956 0.9952968  0.79955155\n",
      " 0.5635681  0.8793269 ]\n",
      "['angry']\n",
      "sending: {\"faces_pos\": [[296, 35, 458, 274, 1]], \"emotions\": [\"angry\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4562154  0.15574901 0.78751326 0.20870174 0.21494402 0.\n",
      " 0.62194514 0.18513085 0.         0.14488661 0.5811812  0.5661924\n",
      " 0.66624033 0.         0.75032663 0.65910566 0.05862935 0.16882396\n",
      " 0.44566035 0.28254116]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[297, 38, 464, 280, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 294, 294]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 294, 294]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35968217 0.17239353 0.60193247 0.25294065 0.14480987 0.\n",
      " 0.07408619 0.0674732  0.         0.10561764 0.44181812 0.33344024\n",
      " 0.5493379  0.         0.7887888  0.65519714 0.10543497 0.23980406\n",
      " 0.3849302  0.03871128]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 50, 472, 296, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 298, 298]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33103022 0.22656308 0.6432523  0.22229642 0.15156986 0.\n",
      " 0.11072141 0.02945329 1.         0.08372352 0.3462149  0.4446479\n",
      " 0.58399165 0.         0.5819799  0.7493815  0.01842456 0.10168955\n",
      " 0.18845436 0.08230468]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[300, 50, 470, 295, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 290, 290]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22368075 0.28806147 0.50805354 0.32568625 0.13812645 0.\n",
      " 0.09557205 0.51076066 0.         0.09995945 0.4985469  0.194386\n",
      " 0.59594464 0.         0.7452847  0.8021163  0.00455174 0.09288386\n",
      " 0.6244725  0.07533117]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[298, 50, 472, 300, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 306, 306]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26554024 0.18587102 0.64285105 0.2753104  0.13933073 0.\n",
      " 0.09540989 0.00376532 0.         0.08949427 0.49949285 0.34397852\n",
      " 0.54671466 0.         0.74963397 0.8152114  0.0151211  0.12710667\n",
      " 0.5768809  0.03433701]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[302, 54, 471, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 302, 302]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17273018 0.30299947 0.5801442  0.35486427 0.10302322 0.\n",
      " 0.10499696 0.20469299 0.         0.07487268 0.5080461  0.36801204\n",
      " 0.6294393  0.         0.7663915  0.66448325 0.14897248 0.25864434\n",
      " 0.56786513 0.01787988]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[300, 49, 472, 306, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30034727 0.22919722 0.5661259  0.31496936 0.20316474 0.\n",
      " 0.20879063 0.4248738  0.         0.09545913 0.4620173  0.72738296\n",
      " 0.5608729  0.         0.7086554  0.6029094  0.7222152  0.502543\n",
      " 0.40695545 0.13453867]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[299, 37, 476, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 296, 296]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 296, 296]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2922197  0.20744686 0.73648316 0.24639858 0.2266971  1.\n",
      " 0.2348736  0.08992294 1.         0.12499791 0.6662976  0.47886518\n",
      " 0.57456833 0.         0.8170633  0.7707863  0.1624801  0.33133066\n",
      " 0.6060051  0.15338562]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[306, 44, 479, 292, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 298, 298]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25615856 0.17345166 0.5860591  0.329244   0.2347055  1.\n",
      " 0.15431175 0.25303438 1.         0.13900729 0.7053502  0.5297922\n",
      " 0.44276136 0.         0.7457921  0.6792255  0.31590837 0.5471087\n",
      " 0.72734416 0.06065191]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[305, 47, 478, 295, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20043612 0.1492254  0.47856134 0.22697298 0.23429877 0.\n",
      " 0.10782596 0.12796615 0.         0.15619567 0.6693109  0.33564585\n",
      " 0.67593366 0.         0.8116839  0.7251913  0.06278042 0.19843927\n",
      " 0.73614943 0.06405962]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[304, 47, 478, 296, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 296, 296]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 298, 298]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5697829  0.65314364 0.11304092 0.3162543  0.13399439 0.\n",
      " 0.07071292 0.07603364 0.         0.06157876 0.42548066 0.59195805\n",
      " 0.597303   0.         0.5967624  0.8010454  0.0475018  0.11507426\n",
      " 0.37475824 0.12725683]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[291, 49, 463, 296, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 326, 348]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8360558  0.57808656 0.27012038 0.37212935 0.14612137 0.\n",
      " 0.09565645 0.16556264 1.         0.25372976 0.44621727 0.37029943\n",
      " 0.4217368  0.         0.73088664 0.6262821  0.33502778 0.71128106\n",
      " 0.55738235 0.0254064 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 39, 421, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 338, 406]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6828727  0.5989348  0.17272316 0.7288588  0.10813268 0.\n",
      " 0.11054729 0.49546143 0.         0.11578589 0.22007737 0.36594296\n",
      " 0.4404156  0.         0.5380132  0.5770306  0.89965314 0.5422926\n",
      " 0.4802618  0.02288673]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[217, 7, 410, 298, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 359, 434]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6763822  0.38583562 0.4173843  0.38156334 0.08098245 1.\n",
      " 0.1293063  0.08033612 0.         0.05066972 0.3448859  0.5908583\n",
      " 0.5293673  0.         0.5637884  0.7906708  0.04140578 0.7035377\n",
      " 0.7830405  0.12092204]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[188, -34, 443, 305, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 376, 452]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53342676 0.30287316 0.6565985  0.37367955 0.06648751 1.\n",
      " 0.18293951 0.07111547 0.         0.02071263 0.34563917 0.3286039\n",
      " 0.48487803 0.         0.49377713 0.65714455 0.1686796  0.5874484\n",
      " 0.5562222  0.07175883]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[221, -39, 486, 323, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 378, 456]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5570999  0.41952989 0.74257034 0.38868353 0.0658458  0.\n",
      " 0.2140976  0.03139376 0.         0.02534663 0.26174104 0.19765635\n",
      " 0.45074207 0.         0.63109165 0.6471496  0.3746     0.6158295\n",
      " 0.5261296  0.04126063]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[230, -38, 506, 339, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 388, 462]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47761476 0.13717726 0.48218626 0.33394587 0.08280009 0.\n",
      " 0.17449236 0.34235644 0.         0.03828019 0.51594096 0.22384436\n",
      " 0.55970836 0.         0.63890576 0.7242759  0.37370005 0.49373594\n",
      " 0.63132143 0.07525837]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[206, -40, 486, 341, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 365, 376]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36454153 0.23412503 0.35363173 0.7310714  0.06102847 0.\n",
      " 0.16790678 0.14646852 1.         0.02084208 0.44294742 0.13811302\n",
      " 0.5268236  0.         0.6865885  0.6483911  0.09873344 0.6942664\n",
      " 0.78102404 0.02838225]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[201, -35, 472, 350, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 378, 390]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28292623 0.32690486 0.4251378  0.73241067 0.06152049 0.\n",
      " 0.09621897 0.07082397 0.         0.04594708 0.5903284  0.46696302\n",
      " 0.4192327  0.         0.75169176 0.57853115 0.1563372  0.07833511\n",
      " 0.7475798  0.03085408]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[234, 21, 445, 334, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27119732 0.28215668 0.23702252 0.68747276 0.09573791 0.\n",
      " 0.12017308 0.03054341 0.         0.08508897 0.7399358  0.09967861\n",
      " 0.33475116 1.         0.68540746 0.5415989  0.6504903  0.23885466\n",
      " 0.54245865 0.03961965]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[229, 20, 452, 347, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 384, 396]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23105131 0.23474663 0.30278158 0.72091305 0.0517197  0.\n",
      " 0.12042274 0.00477007 0.         0.03892012 0.658486   0.2925364\n",
      " 0.34194896 0.         0.5280593  0.58752286 0.30224666 0.13049495\n",
      " 0.57017833 0.0291624 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[220, 21, 450, 352, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 385, 396]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22463366 0.24129091 0.25390056 0.6882701  0.04509322 0.\n",
      " 0.09713561 0.01436614 1.         0.02769189 0.63125825 0.14109911\n",
      " 0.34541702 0.         0.7437584  0.80528194 0.02599313 0.44963542\n",
      " 0.8038125  0.03132813]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[202, 22, 427, 352, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 397, 444]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 391, 406]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3003494  0.20877056 0.43044886 0.36809403 0.05832071 0.\n",
      " 0.13776062 0.23967128 0.         0.04168859 0.3794017  0.1099448\n",
      " 0.47215798 0.         0.68532574 0.7590932  0.20604521 0.78566986\n",
      " 0.9545895  0.03763517]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[281, -10, 549, 361, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 412, 432]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16902429 0.2814701  0.24746686 0.5273684  0.05977462 0.\n",
      " 0.09370521 0.10549554 0.         0.09393525 0.20644186 0.10542254\n",
      " 0.42712775 0.         0.7849733  0.71829325 0.0556521  0.26787144\n",
      " 0.92873836 0.03223833]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[248, 19, 487, 358, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46656293 0.39512873 0.23866186 0.47657672 0.04911659 0.\n",
      " 0.08339202 0.15216674 0.         0.03545837 0.18232171 0.1951441\n",
      " 0.49155137 0.         0.66151536 0.6528193  0.08573927 0.36824477\n",
      " 0.88884294 0.0325219 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[231, 16, 482, 377, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 410, 440]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 390, 416]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39198712 0.38321245 0.29814574 0.44884083 0.05890637 0.\n",
      " 0.10221791 0.03115341 0.         0.06273889 0.17116077 0.26531294\n",
      " 0.5670973  0.         0.8703572  0.6668771  0.0314268  0.18285091\n",
      " 0.7219541  0.04452677]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[244, 7, 492, 374, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 388, 412]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44362625 0.38419187 0.31792513 0.37307322 0.05651917 0.\n",
      " 0.09910905 0.1842728  1.         0.05537665 0.5929282  0.24706681\n",
      " 0.40413123 0.         0.78311396 0.87071025 0.05574418 0.42534956\n",
      " 0.8781515  0.04152652]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[275, 9, 512, 357, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 400, 426]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32500616 0.23558249 0.29361424 0.35747772 0.05968127 0.\n",
      " 0.08430144 0.07324266 0.         0.04861049 0.37453285 0.27968368\n",
      " 0.52664447 0.         0.8303403  0.77311283 0.02934002 0.24938752\n",
      " 0.9631186  0.0319321 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[261, 10, 488, 354, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26159006 0.3060411  0.4261114  0.40045828 0.04438964 0.\n",
      " 0.12994297 0.00649615 0.         0.03282045 0.2359609  0.23247543\n",
      " 0.42665374 0.         0.70782727 0.5434848  0.0101772  0.52704364\n",
      " 0.7751283  0.02411891]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[254, 10, 500, 365, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35053036 0.345221   0.13828751 0.726636   0.05581761 0.\n",
      " 0.09919567 0.23227265 1.         0.0971957  0.67880327 0.1456309\n",
      " 0.36451262 0.         0.7871508  0.69347227 0.11019394 0.69137573\n",
      " 0.8669996  0.0363786 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[261, 9, 497, 360, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 392, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40401682 0.29974928 0.42682758 0.71350557 0.04240963 0.\n",
      " 0.10839969 0.04415547 0.         0.02234718 0.5515909  0.19709365\n",
      " 0.34281126 0.         0.6644716  0.7142866  0.06708852 0.59523624\n",
      " 0.66109186 0.0381944 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[269, 15, 508, 361, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 397, 412]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36037374 0.22233117 0.20076509 0.7096387  0.04315201 0.\n",
      " 0.09844536 0.00396489 1.         0.03570698 0.69144464 0.15360084\n",
      " 0.32152656 0.         0.6878653  0.56404686 0.11989994 0.25659472\n",
      " 0.83922017 0.03119756]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[267, 12, 504, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 401, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25201666 0.32528147 0.24205767 0.38487086 0.03965521 0.\n",
      " 0.08789714 0.01223719 1.         0.03702094 0.17202044 0.08588509\n",
      " 0.43925908 0.         0.8136635  0.6464457  0.05310565 0.3085631\n",
      " 0.8798184  0.03486373]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[252, 19, 494, 364, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31687614 0.449564   0.21940276 0.56506836 0.05024104 0.\n",
      " 0.09087577 0.01613956 0.         0.07392561 0.38081494 0.10507458\n",
      " 0.386715   0.         0.6797656  0.7579687  0.04996131 0.6952738\n",
      " 0.78881365 0.03583515]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 16, 495, 367, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 397, 418]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 376, 408]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3550183  0.4168048  0.37417302 0.3659069  0.03899294 0.\n",
      " 0.08625873 0.08700097 0.         0.05128537 0.21146221 0.1622953\n",
      " 0.37052563 0.         0.8503053  0.6686106  0.01842718 0.5621696\n",
      " 0.46197325 0.0482415 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[239, 14, 489, 363, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 356, 386]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44226366 0.45148844 0.20096052 0.36365598 0.07245883 0.\n",
      " 0.07855978 0.01578029 1.         0.04113417 0.53518516 0.17104177\n",
      " 0.52325827 0.         0.791492   0.86225045 0.00202142 0.5468404\n",
      " 0.8026523  0.03089711]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[271, 2, 511, 343, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 377, 404]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5633814  0.35336173 0.24359928 0.21853597 0.08849501 0.\n",
      " 0.13673474 0.04568604 0.         0.0423047  0.35073116 0.4867373\n",
      " 0.54045844 0.         0.70299435 0.8441137  0.02579433 0.28516942\n",
      " 0.93473464 0.12342296]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[288, 3, 514, 325, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 387, 410]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36951023 0.35293695 0.58435696 0.21592508 0.06993824 0.\n",
      " 0.13504289 0.12299511 0.         0.06410912 0.21545798 0.41582388\n",
      " 0.47015947 0.         0.7841924  0.8184538  0.00469072 0.2446901\n",
      " 0.8170286  0.77454346]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[248, 7, 492, 344, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 384, 410]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28303567 0.24377404 0.48314306 0.36201763 0.08418264 0.\n",
      " 0.12632741 0.29333836 0.         0.02929937 0.16093686 0.17997849\n",
      " 0.56342983 0.         0.76629007 0.81790775 0.0119768  0.24215937\n",
      " 0.6753729  0.06199535]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[246, 10, 488, 354, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 393, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3164231  0.3621979  0.293498   0.2225058  0.06051899 0.\n",
      " 0.13867295 0.19912165 0.         0.03711256 0.32251835 0.29618296\n",
      " 0.6036166  0.         0.69324625 0.89042324 0.01503929 0.25744018\n",
      " 0.7126448  0.10767902]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[268, 7, 508, 351, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 391, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32621998 0.30676112 0.41748774 0.32457894 0.08724818 0.\n",
      " 0.10048157 0.11616362 1.         0.05846031 0.49801025 0.20089212\n",
      " 0.63557863 0.         0.8653328  0.7872433  0.32840994 0.66142154\n",
      " 0.9301193  0.03866669]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 8, 507, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.257374   0.39774626 0.5373799  0.2302496  0.1290123  0.\n",
      " 0.14837645 0.7599316  0.         0.19966865 0.26402393 0.33128417\n",
      " 0.4939659  0.         0.8238401  0.7889463  0.00793358 0.2218919\n",
      " 0.67199343 0.19664125]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[256, 11, 493, 357, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 398, 424]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2120954  0.30999833 0.4309649  0.32916716 0.06337382 0.\n",
      " 0.09885388 0.30547908 1.         0.04302002 0.2728447  0.26352286\n",
      " 0.48391587 0.         0.80653405 0.8147799  0.03135752 0.4384166\n",
      " 0.93518096 0.02326517]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[259, 9, 505, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 398, 424]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2939788  0.5900987  0.29152697 0.222134   0.05537376 0.\n",
      " 0.13526553 0.23230462 0.         0.05499236 0.35650304 0.34489086\n",
      " 0.6474201  0.         0.86873657 0.75407535 0.08446552 0.44628802\n",
      " 0.9043833  0.1739889 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[266, 9, 516, 363, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 381, 402]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32268813 0.39019585 0.15352026 0.40191472 0.04414682 0.\n",
      " 0.09285857 0.10190912 0.         0.02977695 0.34715524 0.25304323\n",
      " 0.40917912 0.         0.8456988  0.77747786 0.0243111  0.6443812\n",
      " 0.83906245 0.02337745]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[286, 9, 529, 363, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 380, 402]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2733101  0.24693811 0.152151   0.37090525 0.04489255 0.\n",
      " 0.09741389 0.04514714 0.         0.01927031 0.61194855 0.19726509\n",
      " 0.39825758 0.         0.767968   0.76806104 0.09449645 0.63294315\n",
      " 0.86498463 0.04417517]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[308, 12, 556, 348, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 383, 408]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22949554 0.4084971  0.30891317 0.21807697 0.04941196 0.\n",
      " 0.12366969 0.09592427 1.         0.03100086 0.3852605  0.23390678\n",
      " 0.42873657 0.         0.61736387 0.7304483  0.02744717 0.77027977\n",
      " 0.7009958  0.15001988]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[303, 12, 551, 348, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 391, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2258131  0.38490778 0.2470313  0.3432942  0.07013828 0.\n",
      " 0.08984362 0.20494185 1.         0.06397801 0.6181462  0.36433786\n",
      " 0.5228102  0.         0.7948566  0.8634832  0.26948807 0.4608436\n",
      " 0.6709665  0.0283966 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[295, 9, 540, 349, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 386, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29170844 0.35418    0.17413174 0.33484367 0.06689633 0.\n",
      " 0.09366456 0.36423534 1.         0.07347995 0.54910207 0.19867752\n",
      " 0.4815002  0.         0.6461025  0.81623256 0.03750846 0.4137448\n",
      " 0.94309825 0.03364857]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[294, 7, 543, 357, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 390, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32206377 0.33283538 0.25557417 0.37677395 0.06308743 0.\n",
      " 0.09817716 0.040497   0.         0.04444646 0.325201   0.18243876\n",
      " 0.465075   0.         0.73343074 0.8381823  0.10965344 0.3628623\n",
      " 0.77060294 0.03450593]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[301, 7, 547, 353, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 418]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2724131  0.34744212 0.36950374 0.3442945  0.04561731 0.\n",
      " 0.09056313 0.02728025 1.         0.02358512 0.3909442  0.40038666\n",
      " 0.40924066 0.         0.79112965 0.68598735 0.14948566 0.33658677\n",
      " 0.7669901  0.03331528]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[294, 10, 548, 356, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 401, 412]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3874104  0.20806895 0.4387061  0.38743588 0.04750047 0.\n",
      " 0.09136484 0.45593107 1.         0.02975887 0.5183222  0.25526512\n",
      " 0.39990878 0.         0.81920767 0.73160315 0.02362595 0.5970367\n",
      " 0.86686933 0.03732511]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[303, 12, 555, 360, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 413, 430]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19667101 0.15735945 0.4223206  0.33420134 0.05139063 0.\n",
      " 0.09509416 0.06676109 1.         0.02784944 0.480622   0.07503321\n",
      " 0.449073   0.         0.75424105 0.7288089  0.02618916 0.2277035\n",
      " 0.48942086 0.02705559]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[284, 24, 534, 368, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 417, 434]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36382324 0.64879334 0.32731178 0.47403452 0.04443977 0.\n",
      " 0.09379546 0.19555719 0.         0.02530225 0.17879882 0.13313033\n",
      " 0.48835224 0.         0.76706296 0.66250515 0.13684818 0.2659572\n",
      " 0.47148314 0.05242178]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[260, 19, 517, 378, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24873975 0.27764133 0.3404914  0.44006902 0.07200827 0.\n",
      " 0.0968091  0.04247318 1.         0.05102494 0.15547794 0.1633131\n",
      " 0.4115925  0.         0.70647573 0.53658044 0.01516347 0.26872897\n",
      " 0.45316696 0.04564702]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[197, 19, 450, 381, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 412, 436]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 382, 408]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2724226  0.2877417  0.34562322 0.45073676 0.07338348 0.\n",
      " 0.10855047 0.26474956 0.         0.04221331 0.15443589 0.19823255\n",
      " 0.4985015  0.         0.7057716  0.6202369  0.06152663 0.23786867\n",
      " 0.6959416  0.04539736]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[194, 12, 450, 376, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 374, 396]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31244344 0.3091998  0.2608485  0.2575795  0.06190283 0.\n",
      " 0.18030377 0.23514055 0.         0.09285384 0.14266305 0.2072294\n",
      " 0.54047894 0.         0.5307884  0.62077147 0.010789   0.6115393\n",
      " 0.6581084  0.19546597]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[256, 9, 497, 349, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 388, 416]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31972057 0.2537983  0.1820133  0.21586257 0.05854783 0.\n",
      " 0.12625523 0.95808303 1.         0.06857569 0.43807366 0.38356715\n",
      " 0.6055216  0.         0.849413   0.74440175 0.16676517 0.32126194\n",
      " 0.763703   0.19778846]\n",
      "['fear']\n",
      "sending: {\"faces_pos\": [[287, 11, 518, 342, 1]], \"emotions\": [\"fear\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 384, 400]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3073142  0.199943   0.57380223 0.21275249 0.12668587 0.\n",
      " 0.16269927 0.21187519 0.         0.11328765 0.19669321 0.3335515\n",
      " 0.5469054  0.         0.8252005  0.8465049  0.04669371 0.19124813\n",
      " 0.9020727  0.30861965]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[264, 7, 497, 354, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 400, 424]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17769909 0.20166017 0.25969002 0.23436475 0.05692638 0.\n",
      " 0.13050644 0.14994472 0.         0.08355837 0.24654405 0.3526375\n",
      " 0.43613717 0.         0.8370858  0.78034663 0.00393926 0.20097688\n",
      " 0.8513214  0.21068469]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[244, 17, 485, 352, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 397, 416]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38517597 0.3631214  0.7185509  0.5080799  0.09006712 0.\n",
      " 0.11022567 0.09230899 1.         0.06637549 0.29225865 0.30661777\n",
      " 0.47501296 0.         0.8434445  0.70847493 0.02659095 0.22377819\n",
      " 0.8293394  0.04871346]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[234, 11, 483, 365, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 398, 412]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.420825   0.30235502 0.76351327 0.448461   0.09566836 0.\n",
      " 0.08935082 0.02370505 1.         0.03962809 0.16482954 0.09950661\n",
      " 0.49648997 0.         0.67815715 0.6405443  0.01425792 0.12167536\n",
      " 0.81302357 0.02901698]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[245, 16, 490, 363, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 407, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3339044  0.3961047  0.44349366 0.4608157  0.10353816 0.\n",
      " 0.08265122 0.00389528 1.         0.04112516 0.2290495  0.24023928\n",
      " 0.62211823 0.         0.5669205  0.6979142  0.06164739 0.0365765\n",
      " 0.45523402 0.0417921 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[230, 20, 480, 365, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 405, 418]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43252188 0.34350067 0.43443403 0.64968914 0.09102791 0.\n",
      " 0.08934147 0.01691259 1.         0.03742435 0.21157336 0.10997719\n",
      " 0.4875093  0.         0.56431794 0.6361702  0.01526605 0.11721833\n",
      " 0.7315459  0.05306204]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[249, 23, 492, 373, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 402, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35922766 0.37829036 0.5965245  0.63485575 0.0678959  0.\n",
      " 0.09552106 0.01999226 1.         0.02651091 0.21333624 0.18775994\n",
      " 0.47364762 0.         0.60716486 0.6707665  0.07865098 0.18103348\n",
      " 0.32928973 0.03349587]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 22, 498, 371, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 416, 422]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43816027 0.32470846 0.69233894 0.45073393 0.09701063 0.\n",
      " 0.09724277 0.0383682  1.         0.04431155 0.21448737 0.22947276\n",
      " 0.57249814 0.         0.72265404 0.7567218  0.00716097 0.05097152\n",
      " 0.4604616  0.04671881]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[246, 23, 497, 369, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 417, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25592896 0.23057629 0.7034338  0.6196202  0.12280196 0.\n",
      " 0.10981627 0.08812644 0.         0.02520443 0.1886449  0.12637253\n",
      " 0.43003082 0.         0.70457375 0.71366614 0.00966927 0.19702102\n",
      " 0.66380054 0.05492345]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[251, 29, 494, 382, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 413, 418]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35835204 0.26557016 0.59401435 0.5639921  0.09654269 0.\n",
      " 0.09768581 0.00401299 1.         0.03343569 0.16283809 0.16330811\n",
      " 0.5073306  0.         0.6534271  0.6836419  0.00227206 0.10649887\n",
      " 0.44812107 0.05126301]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[249, 33, 490, 383, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 404, 404]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.282918   0.26044962 0.44966623 0.60839367 0.10294177 0.\n",
      " 0.10020588 0.00344915 1.         0.03044115 0.15049691 0.04323663\n",
      " 0.4686632  0.         0.49120474 0.66200733 0.00906025 0.36952746\n",
      " 0.22348152 0.06357779]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[245, 30, 488, 379, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 402, 418]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21247463 0.3342562  0.6966891  0.30147773 0.11287188 0.\n",
      " 0.14551383 0.02584599 0.         0.02946899 0.2797616  0.06910306\n",
      " 0.37608138 0.         0.78827655 0.6109956  0.00400895 0.23230444\n",
      " 0.18865784 0.10023081]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 37, 501, 374, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 393, 416]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2257921  0.2701093  0.3428929  0.32088184 0.05330813 0.\n",
      " 0.13031135 0.29557404 0.         0.03254392 0.21748407 0.1604219\n",
      " 0.4671151  0.         0.7735391  0.7744803  0.01819139 0.4730639\n",
      " 0.4528778  0.05495911]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[264, 20, 513, 368, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 392, 418]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27876586 0.33007988 0.46353763 0.44369388 0.05005243 0.\n",
      " 0.08699262 0.09388877 0.         0.03346217 0.21666512 0.19959386\n",
      " 0.4392935  0.         0.6145834  0.7556286  0.03974456 0.6264793\n",
      " 0.7987156  0.03641992]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[277, 12, 525, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 426]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28103966 0.37746307 0.40704572 0.43597668 0.077783   0.\n",
      " 0.08763907 0.23163073 0.         0.02908107 0.1615814  0.17032516\n",
      " 0.39341423 0.         0.6551415  0.7199587  0.37524152 0.42656487\n",
      " 0.6495391  0.03720315]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[283, 9, 520, 358, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 394, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29043934 0.3785839  0.36783963 0.45046288 0.05531421 0.\n",
      " 0.08265855 0.01956911 0.         0.03163082 0.12617001 0.27883655\n",
      " 0.50297886 0.         0.646341   0.67509973 0.57977843 0.6056707\n",
      " 0.7201493  0.03262754]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[283, 4, 533, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 395, 426]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3996234  0.30954674 0.53912055 0.38867527 0.07314041 0.\n",
      " 0.08308325 0.01946131 0.         0.03655712 0.12987813 0.12044643\n",
      " 0.53330076 0.         0.7719219  0.7232359  0.01664069 0.18701382\n",
      " 0.420942   0.04667011]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[271, 9, 519, 359, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 407, 432]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4293238  0.3191705  0.6938929  0.2681486  0.08151117 0.\n",
      " 0.18126875 0.10735329 1.         0.06192206 0.12616275 0.42752358\n",
      " 0.56720567 0.         0.7131186  0.53686374 0.01582765 0.13846406\n",
      " 0.75387037 0.36033627]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[250, 4, 499, 361, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 414, 446]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34472403 0.32889152 0.48773488 0.4292361  0.07900231 0.\n",
      " 0.08336701 0.01786081 1.         0.06980141 0.14188018 0.14982514\n",
      " 0.46232107 0.         0.58319366 0.6748941  0.03288027 0.17496775\n",
      " 0.63472354 0.06675045]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[249, 12, 495, 372, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 430, 466]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45169273 0.26348385 0.3584785  0.4668408  0.07360077 0.\n",
      " 0.10505388 0.01499337 1.         0.02244283 0.20658751 0.2150432\n",
      " 0.54116255 0.         0.72077227 0.6671445  0.00590936 0.22098011\n",
      " 0.49482524 0.05161015]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[241, 5, 497, 377, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 411, 470]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33162954 0.13375407 0.65729254 0.47321272 0.06608985 0.\n",
      " 0.12447385 0.00441001 0.         0.02463154 0.25607422 0.38120896\n",
      " 0.65172344 0.         0.60985464 0.682632   0.01698474 0.22501196\n",
      " 0.4353567  0.06426679]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[230, 3, 487, 393, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 389, 428]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52527833 0.28594145 0.5983583  0.35754743 0.06991363 0.\n",
      " 0.14822021 0.01014205 1.         0.01710165 0.21366206 0.61478746\n",
      " 0.6607924  0.         0.5406639  0.55811906 0.00757921 0.15955855\n",
      " 0.54852873 0.04035011]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[228, -19, 497, 373, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 410, 434]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6273167e-01 1.2924692e-01 7.7481842e-01 3.5970017e-01 6.9300465e-02\n",
      " 0.0000000e+00 1.5318276e-01 5.6312280e-04 1.0000000e+00 1.7038248e-02\n",
      " 2.5155389e-01 4.9924263e-01 5.9651613e-01 0.0000000e+00 4.3571779e-01\n",
      " 7.1190572e-01 3.7155205e-03 1.7039594e-01 3.9699844e-01 6.8908907e-02]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[229, -3, 485, 354, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 419, 420]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34370255 0.24508356 0.4685017  0.38139108 0.07917225 0.\n",
      " 0.11490447 0.01694077 1.         0.01599514 0.31230032 0.21098338\n",
      " 0.55661994 0.         0.6788333  0.68607813 0.00127301 0.11743885\n",
      " 0.28269655 0.06602287]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[230, 12, 486, 374, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 412, 424]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34454086 0.20418398 0.60156447 0.23658608 0.10621686 0.\n",
      " 0.18656115 0.03482345 1.         0.02870342 0.23038077 0.17710839\n",
      " 0.47769874 0.         0.60617435 0.7290861  0.00100273 0.12838459\n",
      " 0.37188563 0.8422386 ]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[233, 34, 484, 386, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 411, 426]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21477957 0.22278705 0.7659486  0.24199669 0.1148442  0.\n",
      " 0.1726578  0.007362   0.         0.05138818 0.3494304  0.42629755\n",
      " 0.6451984  1.         0.861378   0.8671573  0.00624603 0.07941376\n",
      " 0.49494272 0.40247887]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[231, 23, 490, 378, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 419, 430]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3418711  0.4415255  0.44577926 0.6379679  0.05704605 0.\n",
      " 0.08706705 0.03119939 1.         0.03363189 0.21245614 0.15173055\n",
      " 0.526806   0.         0.6513998  0.6345362  0.00766044 0.11791957\n",
      " 0.60735524 0.04002191]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[234, 21, 489, 376, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 412, 430]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32754406 0.4262699  0.3895933  0.41541147 0.06194855 0.\n",
      " 0.09079099 0.11888383 1.         0.03089339 0.25512272 0.15008138\n",
      " 0.49389604 0.         0.6384452  0.6870966  0.00755083 0.11363481\n",
      " 0.44124818 0.04632125]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[233, 24, 488, 384, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 413, 436]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28636476 0.18364066 0.26187724 0.33982107 0.07979804 0.\n",
      " 0.13318957 0.7779104  0.         0.0423736  0.18781655 0.1708161\n",
      " 0.45122606 0.         0.7645106  0.55808824 0.01919847 0.15841287\n",
      " 0.70766944 0.11507694]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[232, 17, 491, 377, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 396, 422]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50029165 0.4377837  0.522643   0.47033915 0.05817723 0.\n",
      " 0.09340059 0.5597759  0.         0.0317242  0.16771795 0.21953481\n",
      " 0.50073445 0.         0.6894937  0.58808976 0.02498649 0.63994765\n",
      " 0.85642856 0.02592055]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[233, 13, 486, 378, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 338, 358]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33378762 0.5490498  0.46982864 0.40330908 0.07303832 0.\n",
      " 0.08835007 0.06533152 0.         0.06856182 0.40604836 0.10421517\n",
      " 0.4815305  0.         0.7126525  0.7564969  0.0173526  0.261506\n",
      " 0.9663194  0.05115892]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[259, 10, 511, 362, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 327, 374]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74250174 0.4096086  0.22536877 0.23336019 0.1082306  0.\n",
      " 0.2871679  0.07598434 0.         0.04718371 0.18687394 0.6652385\n",
      " 0.511973   0.         0.7200139  0.7539877  0.02356783 0.23785515\n",
      " 0.25030753 0.91679686]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[263, 9, 479, 309, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 300, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7327187  0.52795035 0.33094025 0.29650164 0.08277702 0.\n",
      " 0.15404597 0.36285442 0.         0.03517307 0.13314265 0.45245105\n",
      " 0.47319376 0.         0.45871595 0.6376929  0.17871197 0.37314525\n",
      " 0.55253583 0.3782378 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[252, -16, 470, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 286, 300]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7034886  0.5414773  0.15803857 0.38626286 0.11530481 0.\n",
      " 0.1348054  0.11843795 0.         0.04206879 0.15878296 0.47470066\n",
      " 0.48014295 0.         0.43687373 0.51039296 0.03010285 0.24342369\n",
      " 0.39535213 0.08651005]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[213, 1, 407, 273, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 258, 258]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73451567 0.51019883 0.26420155 0.2766587  0.22222999 1.\n",
      " 0.30567294 0.7658034  1.         0.21552192 0.15116107 0.71740854\n",
      " 0.6527245  0.         0.4656551  0.05626814 0.9892265  0.9021383\n",
      " 0.3724981  0.6821071 ]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[230, 11, 399, 262, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 306, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7429396  0.60664374 0.18203698 0.3803444  0.2180602  0.\n",
      " 0.13929969 0.15287821 1.         0.1992859  0.19459997 0.5713641\n",
      " 0.63104254 0.         0.51172763 0.17816806 0.98555726 0.77217996\n",
      " 0.165283   0.09575091]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[255, 63, 400, 279, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 324, 344]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6453164  0.6893373  0.45054522 0.36215907 0.12516995 0.\n",
      " 0.07352346 0.01437054 0.         0.09892718 0.20514536 0.31383666\n",
      " 0.4029061  0.         0.50810695 0.5500031  0.46951357 0.21739471\n",
      " 0.33153024 0.05262078]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[248, 15, 423, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5485727  0.4728828  0.29841247 0.37086585 0.15659128 0.\n",
      " 0.1115481  0.12049265 0.         0.2037927  0.36977383 0.37182444\n",
      " 0.41308492 0.         0.5554631  0.6571709  0.9261515  0.36805734\n",
      " 0.49144953 0.05800938]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[238, 9, 435, 296, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 345, 362]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 369, 394]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2549304  0.26070985 0.18941383 0.73207855 0.05465971 0.\n",
      " 0.09913176 0.03651392 0.         0.06154824 0.15556453 0.12805054\n",
      " 0.47467616 0.         0.7795643  0.7215333  0.09839962 0.13881196\n",
      " 0.7738126  0.03129707]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[244, 13, 458, 316, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 378, 396]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36435497 0.37459397 0.23490143 0.5746451  0.06766956 0.\n",
      " 0.12226489 0.08289643 0.         0.05056076 0.21444267 0.6311497\n",
      " 0.4309828  0.         0.6548264  0.6173868  0.217356   0.18885157\n",
      " 0.87821734 0.03050326]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[246, 8, 472, 337, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 382, 400]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4452674  0.47141355 0.19890377 0.702893   0.07720002 0.\n",
      " 0.14269383 0.06379143 0.         0.06028572 0.3489426  0.50952154\n",
      " 0.38708204 0.         0.6506492  0.5922513  0.5288538  0.82608736\n",
      " 0.75240165 0.03422851]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[240, 15, 484, 346, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 388, 414]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37732437 0.36587805 0.5270093  0.39064196 0.0818061  0.\n",
      " 0.16213702 0.02184418 0.         0.11259738 0.36389855 0.4712033\n",
      " 0.5402869  0.         0.5049488  0.58146375 0.01975524 0.74195284\n",
      " 0.8742357  0.02817953]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[242, 16, 482, 349, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 384, 400]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39741835 0.4599743  0.31069487 0.60393184 0.07920166 0.\n",
      " 0.13544697 0.09463581 0.         0.0733128  0.37000746 0.48202738\n",
      " 0.50919664 0.         0.70955044 0.60230905 0.45708984 0.32134494\n",
      " 0.7186702  0.02855482]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[246, 9, 476, 355, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 385, 412]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47657692 0.51882505 0.26624906 0.58182055 0.08688601 0.\n",
      " 0.13429865 0.42662534 1.         0.12448633 0.20260286 0.44011164\n",
      " 0.51716125 0.         0.41617268 0.48811615 0.03293794 0.84406686\n",
      " 0.77131015 0.02076283]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[245, 17, 480, 351, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 386, 408]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48583508 0.3564095  0.5506455  0.5239304  0.06684808 0.\n",
      " 0.12891147 0.25817567 0.         0.04624148 0.19042937 0.5745146\n",
      " 0.5870213  0.         0.55296475 0.7399309  0.00874935 0.16042347\n",
      " 0.6816524  0.0289181 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[242, 8, 485, 352, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 385, 396]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42454043 0.32811    0.37181073 0.5740524  0.07837041 0.\n",
      " 0.15438955 0.0212794  0.         0.08354626 0.13441402 0.51821256\n",
      " 0.42510512 0.         0.7853078  0.64521676 0.6441694  0.6324204\n",
      " 0.9222939  0.03903504]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[245, 12, 478, 354, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 387, 398]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5045284  0.39934638 0.47948295 0.3682194  0.08668897 0.\n",
      " 0.13470478 0.3453501  1.         0.09970438 0.26187742 0.69810545\n",
      " 0.49234998 0.         0.53394717 0.5792715  0.38227168 0.60966396\n",
      " 0.91270083 0.03210584]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[250, 22, 479, 353, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 367, 388]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38948986 0.4535171  0.18718971 0.46981138 0.07341254 0.\n",
      " 0.11430191 0.09471659 0.         0.04928515 0.20258847 0.29468942\n",
      " 0.5541198  0.         0.68835634 0.6187968  0.13459802 0.50958484\n",
      " 0.8233031  0.02901653]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[246, 22, 480, 355, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 361, 392]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32687643 0.476441   0.605294   0.2299152  0.09198219 0.\n",
      " 0.171883   0.36728132 0.         0.0868066  0.1861613  0.77202684\n",
      " 0.5078715  0.         0.65701157 0.6941202  0.08489138 0.6069874\n",
      " 0.57352316 0.20183815]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[255, 11, 493, 336, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 356, 380]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71729815 0.6468922  0.43551195 0.5593897  0.08760406 0.\n",
      " 0.12833218 0.03393726 1.         0.09013331 0.26664945 0.6768545\n",
      " 0.43981692 0.         0.62416047 0.656289   0.22228584 0.46737516\n",
      " 0.6788893  0.03258828]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[284, 1, 505, 329, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5640833  0.6644515  0.24129735 0.3372148  0.08277575 1.\n",
      " 0.18500462 0.21980181 0.         0.08152874 0.18607013 0.6569062\n",
      " 0.44452485 0.         0.50889343 0.3760012  0.12963913 0.6107994\n",
      " 0.4573982  0.0515193 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[278, 8, 492, 325, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 361, 384]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 361, 374]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6069104  0.48356572 0.41838226 0.38816854 0.06467066 0.\n",
      " 0.2150671  0.01410433 0.         0.03018269 0.30064213 0.56120926\n",
      " 0.42800653 0.         0.58378094 0.7146051  0.13884346 0.64631486\n",
      " 0.3801073  0.02841249]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[270, 10, 497, 330, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.523383   0.43168214 0.4320214  0.35093015 0.0688919  0.\n",
      " 0.18473111 0.13196872 1.         0.09146027 0.20725209 0.4437292\n",
      " 0.52317095 0.         0.5616827  0.5409684  0.89435136 0.7493415\n",
      " 0.6572759  0.02219127]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[261, 18, 488, 331, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 365, 390]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 333, 352]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43726882 0.25178134 0.27131546 0.33247834 0.06682071 0.\n",
      " 0.10717004 0.7323753  0.         0.03154591 0.243372   0.2980133\n",
      " 0.47889125 0.         0.79669523 0.7104457  0.57644874 0.2829004\n",
      " 0.830996   0.03458468]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[265, 8, 487, 334, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 337, 356]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7277008  0.4437381  0.19056278 0.33272517 0.08307818 0.\n",
      " 0.10231702 0.17966412 0.         0.03284057 0.12595141 0.5756881\n",
      " 0.488719   0.         0.5418697  0.71781224 0.05009053 0.6634919\n",
      " 0.5082596  0.03897409]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[259, 10, 464, 305, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 346, 366]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5904376  0.22497107 0.5331628  0.38256794 0.0803001  0.\n",
      " 0.13782406 0.0095216  0.         0.04052063 0.17540559 0.52791846\n",
      " 0.46606123 0.         0.5518411  0.7249674  0.4545455  0.4344578\n",
      " 0.8621738  0.02966634]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[258, 11, 465, 308, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 343, 366]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4433415  0.43433163 0.32774776 0.3812413  0.04392206 0.\n",
      " 0.10695848 0.00083799 0.         0.02344595 0.1624207  0.37832227\n",
      " 0.46534368 0.         0.6351814  0.48844102 0.12991622 0.6936217\n",
      " 0.8208442  0.02966024]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[265, 11, 479, 317, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 340, 364]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4699238  0.48452756 0.3349634  0.34959763 0.05729762 0.\n",
      " 0.10575386 0.28859952 1.         0.0373388  0.25630945 0.28411877\n",
      " 0.36339578 0.         0.7813704  0.82038885 0.8685638  0.54241896\n",
      " 0.62901413 0.04965658]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 7, 471, 314, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 302, 338]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52301246 0.3105159  0.55729765 0.33526462 0.07682562 0.\n",
      " 0.1243417  0.10420725 0.         0.03759161 0.17105518 0.28748465\n",
      " 0.46509728 0.         0.76402974 0.68643403 0.17986807 0.62761134\n",
      " 0.8471202  0.02714874]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[251, 6, 459, 311, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 308, 334]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7299371  0.57841307 0.2956459  0.49220034 0.22290353 1.\n",
      " 0.17970416 0.00850218 1.         0.09082032 0.16963737 0.6456747\n",
      " 0.664116   0.         0.49226367 0.61809784 0.40464655 0.4604332\n",
      " 0.80968124 0.06017938]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[257, -7, 467, 275, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 335, 358]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8176426  0.6077245  0.26493514 0.40382832 0.15096907 1.\n",
      " 0.2458678  0.5706882  0.         0.07125957 0.16746344 0.33317974\n",
      " 0.56700355 0.         0.6952637  0.2614474  0.8095166  0.73784363\n",
      " 0.24913922 0.05449554]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[269, 2, 485, 281, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 347, 372]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74357355 0.54423296 0.33438855 0.35486978 0.09819378 0.\n",
      " 0.1105997  0.01313035 0.         0.02343596 0.3262597  0.45502976\n",
      " 0.5417678  0.         0.68193835 0.4523378  0.7933351  0.36602902\n",
      " 0.7517565  0.11801262]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[260, 7, 469, 307, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6161368  0.52293986 0.47644085 0.24998903 0.1124658  0.\n",
      " 0.30280757 0.02928104 1.         0.04530789 0.41225776 0.40627426\n",
      " 0.622035   0.         0.68496454 0.46869355 0.6058858  0.53207487\n",
      " 0.9145662  0.27646112]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 6, 463, 317, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 308, 330]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 320, 346]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7396396  0.45928213 0.21898204 0.3168077  0.20510332 0.\n",
      " 0.20282723 0.45268545 0.         0.06138961 0.25081205 0.6652922\n",
      " 0.38623142 0.         0.36578947 0.29578894 0.74880093 0.5905465\n",
      " 0.1143328  0.251736  ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[308, 6, 503, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5944067  0.22632122 0.325488   0.39430913 0.15932043 0.\n",
      " 0.15976405 0.07222293 0.         0.0957509  0.26757434 0.37663677\n",
      " 0.40760103 0.         0.56462276 0.15509573 0.95009345 0.7526795\n",
      " 0.36128864 0.10758165]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[316, 3, 526, 293, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 312, 336]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56217617 0.36884654 0.25686693 0.6105546  0.13862169 1.\n",
      " 0.17382686 0.8248001  1.         0.12678744 0.34464896 0.5535045\n",
      " 0.51157326 0.         0.39864492 0.35176426 0.9841599  0.8451711\n",
      " 0.12110262 0.02037794]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[305, 15, 506, 288, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 329, 354]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44501492 0.301244   0.5390626  0.39158386 0.23927736 1.\n",
      " 0.22252597 0.01508917 0.         0.36022803 0.2911067  0.3374018\n",
      " 0.31936347 1.         0.2808965  0.09362921 0.9996164  0.7455751\n",
      " 0.09943046 0.02597116]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[293, 4, 500, 284, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5064776  0.6004322  0.2803191  0.33822638 0.14843908 0.\n",
      " 0.11764848 0.23875627 0.         0.13681644 0.47369576 0.5984403\n",
      " 0.4265286  0.         0.66023326 0.79111403 0.55083144 0.6504999\n",
      " 0.46121013 0.03075315]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[274, 5, 477, 300, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 304, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42546463 0.30564865 0.65038484 0.38905218 0.09079324 0.\n",
      " 0.13255984 0.04205383 0.         0.03559883 0.10228027 0.78944093\n",
      " 0.4814854  0.         0.47557777 0.6139417  0.10460678 0.3718563\n",
      " 0.73020107 0.04116923]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[259, 9, 436, 278, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28681615 0.15808044 0.6291815  0.318293   0.17540348 0.\n",
      " 0.25230938 0.11335861 1.         0.04055296 0.32731393 0.47662458\n",
      " 0.48370358 0.         0.6262618  0.57310736 0.40992874 0.6212696\n",
      " 0.13792084 0.13022669]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 10, 432, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 311, 330]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 307, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.483781   0.3684918  0.564488   0.24608742 0.09819259 0.\n",
      " 0.19972084 0.2306371  1.         0.07321116 0.20021358 0.685103\n",
      " 0.42586833 0.         0.44167632 0.3665684  0.2637161  0.6008518\n",
      " 0.55209166 0.1001684 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[259, 9, 438, 284, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37536943 0.21456361 0.63858473 0.2934656  0.07260218 0.\n",
      " 0.17143464 0.2539297  0.         0.04617313 0.1654846  0.60912144\n",
      " 0.48212647 0.         0.4988384  0.41769075 0.0095923  0.28270146\n",
      " 0.603522   0.04137377]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 8, 436, 280, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 314, 334]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 340]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39850566 0.36439505 0.40587616 0.43436962 0.06594749 0.\n",
      " 0.14188136 0.05451012 1.         0.06322007 0.1376974  0.40990415\n",
      " 0.43776202 0.         0.593982   0.41681692 0.09968769 0.31318295\n",
      " 0.77611846 0.02626849]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 8, 444, 288, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45954305 0.5077828  0.42255563 0.7117051  0.06491785 0.\n",
      " 0.15051761 0.02342651 0.         0.04138235 0.16347283 0.31154582\n",
      " 0.45487982 0.         0.42836323 0.670609   0.02315475 0.3869548\n",
      " 0.91044664 0.03782634]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 7, 444, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 317, 334]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46375275 0.41440058 0.3872892  0.5597833  0.0841921  0.\n",
      " 0.11139327 0.02562143 0.         0.0645282  0.2193175  0.1162852\n",
      " 0.47216323 0.         0.41399515 0.64935166 0.01071026 0.15384927\n",
      " 0.63492584 0.02833991]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 11, 443, 289, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 336]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37146938 0.38863188 0.6216158  0.7272184  0.04252394 0.\n",
      " 0.11035299 0.08431725 0.         0.07304198 0.20310734 0.360345\n",
      " 0.44116724 0.         0.6625458  0.7400343  0.01502048 0.61367065\n",
      " 0.7907686  0.02747886]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 11, 442, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 319, 342]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35785198 0.5380193  0.40554705 0.7235939  0.061274   0.\n",
      " 0.11136577 0.18518533 1.         0.11362338 0.2033879  0.3248131\n",
      " 0.41948998 0.         0.55684114 0.62223303 0.0308362  0.31580046\n",
      " 0.6148043  0.02986947]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[255, 11, 444, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43490028 0.40763912 0.4592781  0.7455142  0.12012448 0.\n",
      " 0.09765007 0.672481   0.         0.14272541 0.15535307 0.49204433\n",
      " 0.47468346 0.         0.47261202 0.09478273 0.9993512  0.6752906\n",
      " 0.11976712 0.05057932]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[255, 6, 443, 291, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 293, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2667467  0.32651427 0.7538452  0.3023856  0.25251377 0.\n",
      " 0.5322731  0.15321548 0.         0.12599838 0.48415807 0.1853281\n",
      " 0.6115533  0.         0.6299338  0.33586234 0.02332751 0.44327852\n",
      " 0.54569924 0.86347544]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 5, 426, 268, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 295, 318]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21100733 0.1190705  0.8129264  0.30640557 0.23800813 0.\n",
      " 0.4024648  0.06383499 1.         0.08160339 0.3107211  0.6602127\n",
      " 0.64042336 0.         0.65008676 0.5751888  0.02614382 0.15419625\n",
      " 0.3874499  0.5175188 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[252, 2, 430, 268, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 297, 314]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29050285 0.21510816 0.8550091  0.26754752 0.19567345 0.\n",
      " 0.41098282 0.0516536  0.         0.11802645 0.33239755 0.40701663\n",
      " 0.5810334  0.         0.6206916  0.43462682 0.00737868 0.2487061\n",
      " 0.5410859  0.40709487]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[255, 3, 434, 269, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 301, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22181508 0.20437314 0.8279377  0.302853   0.24870545 1.\n",
      " 0.50926214 0.30341563 0.         0.08079121 0.39718938 0.44782817\n",
      " 0.630054   0.         0.5977783  0.5315492  0.04619171 0.18454827\n",
      " 0.3995231  0.5539793 ]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[256, 9, 434, 272, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 311, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24997744 0.15449388 0.4323679  0.23216613 0.23809649 1.\n",
      " 0.25475577 0.353946   0.         0.11678283 0.43420312 0.7011747\n",
      " 0.71742326 0.         0.70528483 0.76611793 0.00824995 0.30233222\n",
      " 0.3911315  0.21440406]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 7, 435, 275, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 308, 320]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6604207  0.55866396 0.39996803 0.35936394 0.05754113 0.\n",
      " 0.12316153 0.15170352 0.         0.04626343 0.16506226 0.48529142\n",
      " 0.48081753 0.         0.4521637  0.61188924 0.11469384 0.60887706\n",
      " 0.6747051  0.02321332]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[254, 10, 437, 285, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 307, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28991807 0.21398035 0.20590149 0.3430912  0.08733666 0.\n",
      " 0.14712326 0.24347405 1.         0.05087022 0.38356948 0.49369392\n",
      " 0.47200698 0.         0.82410955 0.72708064 0.08226031 0.14901777\n",
      " 0.6812862  0.04499244]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[258, 14, 434, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 326]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41408718 0.39317888 0.28777257 0.33973506 0.10975681 0.\n",
      " 0.13872318 0.7603036  1.         0.05571065 0.24566345 0.16670412\n",
      " 0.39885005 0.         0.65762025 0.5652517  0.2938169  0.32464886\n",
      " 0.33173823 0.02387982]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[256, 12, 432, 281, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 309, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37221104 0.24622853 0.60180914 0.3428092  0.08241385 0.\n",
      " 0.15903507 0.37124944 0.         0.0371888  0.19143154 0.28103542\n",
      " 0.41497228 0.         0.46481365 0.7149004  0.15773676 0.49382052\n",
      " 0.70569074 0.03055322]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[257, 10, 434, 282, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 322]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28871474 0.37158617 0.34826213 0.34128955 0.09367938 0.\n",
      " 0.17356339 0.29774225 0.         0.03373298 0.2173739  0.32532075\n",
      " 0.366389   0.         0.51019    0.33307984 0.5194808  0.52286667\n",
      " 0.23022887 0.02547708]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[257, 12, 434, 283, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 316, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92233586 0.86390287 0.04817385 0.74156386 0.05928267 0.\n",
      " 0.15871447 0.00533394 1.         0.04083455 0.2823383  0.6673495\n",
      " 0.4467108  0.         0.6762723  0.53053033 0.17596382 0.34642464\n",
      " 0.36323977 0.04359433]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[257, 21, 437, 290, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 320, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88727343 0.8231938  0.12473802 0.7592959  0.05591419 0.\n",
      " 0.12299985 0.02044439 1.         0.02630724 0.24940433 0.63928366\n",
      " 0.4608261  0.         0.45717534 0.45074734 0.11249225 0.53015363\n",
      " 0.34231997 0.04311037]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[255, 19, 437, 290, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 324]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87102765 0.8331016  0.05847194 0.7622217  0.04977741 0.\n",
      " 0.12133636 0.07571001 1.         0.02712998 0.20188606 0.5638785\n",
      " 0.38627914 0.         0.64641804 0.38138294 0.65655345 0.7306748\n",
      " 0.47463137 0.04481447]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[259, 19, 438, 294, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 317, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8093753  0.68926114 0.18556702 0.76255804 0.05716024 0.\n",
      " 0.12143032 0.02815774 0.         0.03408308 0.30231002 0.6032132\n",
      " 0.3917568  0.         0.49073726 0.4887794  0.39233115 0.7312873\n",
      " 0.48444372 0.04065493]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[259, 20, 437, 292, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77761036 0.69285816 0.05605221 0.75937444 0.06214595 0.\n",
      " 0.10948735 0.03045313 1.         0.03581627 0.30065337 0.25004807\n",
      " 0.4012592  0.         0.4916583  0.36726066 0.73539406 0.7524576\n",
      " 0.74327254 0.04691581]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[258, 16, 438, 291, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 320, 328]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31827718 0.23471083 0.5354485  0.32482654 0.08471431 1.\n",
      " 0.10803484 0.11891194 1.         0.06970644 0.5123866  0.3990902\n",
      " 0.4653561  0.         0.8220743  0.88119215 0.24050598 0.5812904\n",
      " 0.7657168  0.02953574]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 17, 442, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 322, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3000762  0.24315494 0.51167446 0.33117115 0.04853126 1.\n",
      " 0.14277783 0.0244009  0.         0.02878023 0.34762034 0.35556707\n",
      " 0.40011576 0.         0.7820602  0.7074815  0.0574929  0.64147896\n",
      " 0.72885007 0.04950396]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[258, 20, 442, 294, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 323, 334]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43098485 0.35853937 0.7423354  0.3346365  0.07264449 1.\n",
      " 0.15655594 0.23226209 1.         0.03395283 0.39634264 0.43557942\n",
      " 0.417734   0.         0.8935752  0.7059628  0.0451028  0.53248215\n",
      " 0.89998007 0.03946077]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[257, 17, 443, 295, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4709965  0.26853856 0.6508347  0.33105153 0.04847892 1.\n",
      " 0.1435121  0.1874758  0.         0.03716998 0.27918673 0.4167714\n",
      " 0.40197834 0.         0.8044317  0.6960787  0.01488478 0.65012044\n",
      " 0.8330954  0.03743402]\n",
      "['sad']\n",
      "sending: {\"faces_pos\": [[259, 17, 445, 297, 1]], \"emotions\": [\"sad\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 319, 338]) to 112\n",
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 318, 338]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25903004 0.26812038 0.54531723 0.34164327 0.07741232 1.\n",
      " 0.17079246 0.5254412  0.         0.08282101 0.26884073 0.78672624\n",
      " 0.4658198  0.         0.6683368  0.469534   0.219376   0.30242947\n",
      " 0.5553072  0.04137487]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 9, 444, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 320, 340]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52738744 0.5642529  0.58826566 0.36051795 0.06351269 0.\n",
      " 0.13336194 0.15924275 0.         0.03907869 0.17834485 0.65703213\n",
      " 0.43952698 0.         0.59505725 0.48780206 0.20268975 0.3499079\n",
      " 0.69579345 0.02714139]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[257, 8, 443, 291, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 317, 340]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54341704 0.22070242 0.573193   0.3315702  0.0618739  0.\n",
      " 0.1203099  0.07075381 0.         0.06521418 0.2464912  0.62757427\n",
      " 0.50427514 0.         0.6146625  0.84757113 0.03315178 0.22770321\n",
      " 0.8482856  0.06058513]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 9, 444, 293, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 323, 338]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4032802  0.5058664  0.25776723 0.35488808 0.05788637 0.\n",
      " 0.12041434 0.0873605  0.         0.05535154 0.14827053 0.31720263\n",
      " 0.44803816 0.         0.49322668 0.70351    0.09742457 0.53885686\n",
      " 0.73826885 0.03372348]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 5, 444, 290, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 327, 342]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45496243 0.3525454  0.22792411 0.34278247 0.05965569 0.\n",
      " 0.13549857 0.0464728  0.         0.04875604 0.17453673 0.8245125\n",
      " 0.47250062 0.         0.71254957 0.5023167  0.97818255 0.89773923\n",
      " 0.7869742  0.02794173]\n",
      "['surprise']\n",
      "sending: {\"faces_pos\": [[254, 13, 442, 297, 1]], \"emotions\": [\"surprise\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 325, 340]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46831384 0.22885181 0.61996305 0.34030837 0.04831355 1.\n",
      " 0.18133382 0.14900723 0.         0.08512474 0.30802417 0.47105\n",
      " 0.41306767 0.         0.8250727  0.67358893 0.5977472  0.6190714\n",
      " 0.4641051  0.02543186]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[253, 13, 444, 299, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 326, 340]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40293163 0.24534923 0.36434558 0.34025013 0.0518778  1.\n",
      " 0.13597228 0.04909785 1.         0.07817101 0.24000014 0.40902394\n",
      " 0.34741268 0.         0.72701895 0.6273131  0.5340574  0.660448\n",
      " 0.6251424  0.02475769]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 13, 443, 297, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n",
      "INFO:root:detecting faces...\n",
      "INFO:root:detecting landmarks...\n",
      "INFO:root:RESCALING WARNING: image_operations.extract_face_from_bbox() is rescaling cropped img with shape torch.Size([3, 324, 332]) to 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30685404 0.23071906 0.6033436  0.3387988  0.06480289 0.\n",
      " 0.13449997 0.14610359 1.         0.06855319 0.23451696 0.70696026\n",
      " 0.4286753  0.         0.7990569  0.6234922  0.66801476 0.5194364\n",
      " 0.8241308  0.02995273]\n",
      "['neutral']\n",
      "sending: {\"faces_pos\": [[254, 15, 442, 299, 1]], \"emotions\": [\"neutral\"], \"no_faces\": 1}\n",
      "server acknowledged reception of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:detecting aus...\n"
     ]
    }
   ],
   "source": [
    "%run camera_server/video_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6796b-9a8d-4cbd-9204-c00d63e3c035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
